{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5c6077-14a4-4760-aa3a-67c14be3bbf3",
   "metadata": {},
   "source": [
    "# Running TB Profiler on SRA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a129d15-cdda-4779-960b-f23b94688af7",
   "metadata": {},
   "source": [
    "## Exploring On Own Computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6575136-639f-4853-8ddb-3cda18a23abe",
   "metadata": {},
   "source": [
    "[TBProfiler](https://github.com/jodyphelan/TBProfiler)\n",
    "\n",
    "[SRA](https://www.ncbi.nlm.nih.gov/sra)\n",
    "\n",
    "I download a few sample data files on my computer, follow the installation instructions, and run a few test computations. I know there are hundreds of data files that I may want to analyze and I don't want to tie up my computer. I'm going to move these commands from my computer to an HTC system, using an Access Point and HTCondor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a5305-5901-491b-a74f-eddc29090a5e",
   "metadata": {},
   "source": [
    "## Identifying Job Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce59e7-9578-48d1-8e68-2ec0dff5107d",
   "metadata": {},
   "source": [
    "Based on our experience running on our own computer, we can see the following components that we need to account for or recreate for our jobs: \n",
    "* A single job corresponds to a single sample, we will start with **48 samples** (for now) to run\n",
    "* **Input:** Pre-stage the needed fastq files or download in the job; file name convention is `SRA####_1.fastq` and `SRA####_2.fastq`\n",
    "* **Software environment:** installing tb-profiler using conda\n",
    "* Command format is: `tb-profiler profile -1 SRA####_1.fastq -2 SRA####_2.fastq -t 1 -p SRA####`\n",
    "* **Output:** Output is in a \"results\" folder and has the naming convention: `SRA####.results.json`\n",
    "* **Compute Resources:** 1 core, 4GB of disk space, unknown memory\n",
    "* **Time:** one job takes a few minutes to run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e9bd2-ae97-441f-85e2-993fbe7d627b",
   "metadata": {},
   "source": [
    "## Stage Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed17b8a-2f5d-4f83-97cd-3761f199c051",
   "metadata": {},
   "source": [
    "First, how will fetch the **input** data to our jobs? We have a few options: \n",
    "1) download the data directly from NCBI in the job, using `sra-toolkit`\n",
    "2) upload inputs to our home folder on an Access Point, use HTCondor's default file transfer to fetch the inputs to jobs\n",
    "3) upload the inputs to an OSDF folder, use OSDF URLs to fetch inputs to jobs\n",
    "\n",
    "We generally recommend the last two options because they are more visible and managed by HTCondor. In this example, the inputs are large enough (around 1GB or larger) and likely to be reused, so using option 3 is the best choice. For this example, we've pre-staged the data on a public OSDF folder, accessible via the path `/osgconnect/public/osg/tutorial-tb-profiler/sra-data-files/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a819a7-cc91-49b0-ae53-6e870624c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stashcp --list-dir /osgconnect/public/osg/tutorial-tb-profiler/tb-sra-files ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ea5b8-b87e-4230-bd58-0dc5a6cc2fa4",
   "metadata": {},
   "source": [
    "One thing we can do now to make life easier for ourselves later is to generate a list of the input files to use later for our job submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fbda08c-c6d3-46a8-af2a-ed8d7ea85bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR18715196\n",
      "SRR18715198\n",
      "SRR18715199\n",
      "SRR18715200\n",
      "SRR18715201\n",
      "SRR18715202\n",
      "SRR18715203\n",
      "SRR18715204\n",
      "SRR18715205\n",
      "SRR18715206\n"
     ]
    }
   ],
   "source": [
    "head -n 10 SraAccList.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d6ce0a-3d77-40c6-b046-2923c1384853",
   "metadata": {},
   "source": [
    "## Prepare and Test Software Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd71cf-2579-4cc2-b27e-7ba12e9aa59e",
   "metadata": {},
   "source": [
    "> [These training materials](https://portal.osg-htc.org/documentation/support_and_training/training/osgusertraining/#using-containerized-software-on-the-open-science-pool) provide a nice introduction to containers in the OSPool. \n",
    "\n",
    "For this job, we will recreate our conda environment in a container. \n",
    "\n",
    "Containers can be created (or \"built\") from a definition file. The definition file below includes some standard configuration for setting up a conda environment. It has been customized in the `%post` section where the specific tb-profiler installation commands are inserted (directly from the [installation instructions](https://github.com/jodyphelan/TBProfiler#conda)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce580df0-748c-4c67-92a2-7739bd4177fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap: docker\n",
      "From: continuumio/miniconda3:23.3.1-0\n",
      "\n",
      "%environment\n",
      "  export PATH=/opt/conda/bin:$PATH\n",
      "  . /opt/conda/etc/profile.d/conda.sh\n",
      "  conda activate\n",
      "\n",
      "%post\n",
      "  conda config --add channels defaults\n",
      "  conda config --add channels bioconda\n",
      "  conda config --add channels conda-forge\n",
      "  conda install -y -c bioconda tb-profiler\n"
     ]
    }
   ],
   "source": [
    "cat build/tb-profiler.def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b475c7c-cbcf-4e21-899e-211349d05083",
   "metadata": {},
   "source": [
    "To build the container in the `build` folder, you would run this sequence of commands: \n",
    "\n",
    "```\n",
    "cd build\n",
    "apptainer build tb-profiler.sif tb-profiler.def\n",
    "cd ..\n",
    "```\n",
    "\n",
    "You do not need to build the container to participate in the tutorial (it takes a long time to build!), so we have a copy pre-staged in a public location that can be used for submitting jobs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c226fc3-249d-470d-8435-9ff17b33f5f6",
   "metadata": {},
   "source": [
    "Similarly, once the container is built, the following sequence of commands can be used to explore/test the container: \n",
    "\n",
    "```\n",
    "##  to be run in the command line: \n",
    "# download the container if you didn't build a local copy\n",
    "stashcp /ospool/PROTECTED/christina.koch/singularity_imgs/tb-profiler-test.sif build/\n",
    "# start the container with a shell\n",
    "apptainer shell build/tb-profiler.sif\n",
    "# run the tb-profiler command to see if it is in the container\n",
    "tb-profiler\n",
    "# see where the tb-profiler program is installed in the container\n",
    "which tb-profiler\n",
    "# exit the container\n",
    "exit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63a0a0-bb83-4096-a3e5-d8a3272e08a8",
   "metadata": {},
   "source": [
    "## Organize Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad230be4-bf0f-4184-8b3c-b6edfc429cdf",
   "metadata": {},
   "source": [
    "We've already sectioned off our software environment (container and definition files) into their own folder. Our input files are staged in the OSDF. The remaining thing to think about are the outputs. We will have the `.json` file produced for each sample, which we will put in an `outputs` folder, and job log, error and stdout files, which we will put in a `logs` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c3f7494-8dce-428d-817f-a4b171a16ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f000018b-00c6-43b8-9678-469977aa24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e0487-6312-461f-b6af-01dc930b1569",
   "metadata": {},
   "source": [
    "## Submit One Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e834c31-2965-49bf-aaba-9b1db14f8c9b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1053950-faa0-438d-b431-16870b975a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe = container\n",
      "container_image = osdf:///osgconnect/public/osg/tutorial-tb-profiler/tb-profiler-test.sif\n",
      "transfer_executable = false\n",
      "\n",
      "executable = /opt/conda/bin/tb-profiler\n",
      "arguments = tb-profiler profile -1 $(sequence_read)_1.fastq -2 $(sequence_read)_2.fastq -t 1 -p $(sequence_read)\n",
      "\n",
      "data_path = osdf:///osgconnect/public/osg/tutorial-tb-profiler/tb-sra-files/$(sequence_read)\n",
      "transfer_input_files = $(data_path)/$(sequence_read)_1.fastq, $(data_path)/$(sequence_read)_2.fastq\n",
      "\n",
      "output_file = $(sequence_read).results.json\n",
      "transfer_output_files = results/$(output_file)\n",
      "transfer_output_remaps = \"$(output_file) = outputs/$(output_file)\"\n",
      "\n",
      "log = logs/tb-profiler.log\n",
      "error = logs/$(sequence_read).$(Cluster).$(Process).err\n",
      "output = logs/$(sequence_read).$(Cluster).$(Process).out\n",
      "\n",
      "requirements = (Target.has_avx == true)\n",
      "\n",
      "request_cpus = 1\n",
      "request_memory = 4GB\n",
      "request_disk = 4GB\n",
      "\n",
      "sequence_read = SRR18714896\n",
      "queue\n",
      "#queue sequence_read from SraAccList.csv\n"
     ]
    }
   ],
   "source": [
    "cat tb-profiler.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "546e2202-82c8-4bc3-a67c-fa760929b99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job(s).\n",
      "1 job(s) submitted to cluster 192393.\n"
     ]
    }
   ],
   "source": [
    "condor_submit tb-profiler.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb2e1992-0343-4a07-a945-d969968654f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- Schedd: ap40.uw.osg-htc.org : <128.105.68.92:9618?... @ 07/11/23 22:28:28\n",
      "OWNER        BATCH_NAME    SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS\n",
      "christina.ko ID: 192393   7/11 22:22      _      _      1      1 192393.0\n",
      "\n",
      "Total for query: 1 jobs; 0 completed, 0 removed, 1 idle, 0 running, 0 held, 0 suspended \n",
      "Total for christina.koch: 1 jobs; 0 completed, 0 removed, 1 idle, 0 running, 0 held, 0 suspended \n",
      "Total for all users: 8240 jobs; 0 completed, 0 removed, 1043 idle, 6572 running, 625 held, 0 suspended\n",
      "\n"
     ]
    }
   ],
   "source": [
    "condor_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d90bb-4ecf-4a11-9509-b505d0dfbb10",
   "metadata": {},
   "source": [
    "## Submit Multiple Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc6a24-83c4-48f8-93ab-6211ad1f29c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f25422b-f0bb-4f20-ac49-8893977c974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "condor_submit tb-profiler.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b521319-31f3-43aa-b0c0-e7db340f55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "condor_q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
